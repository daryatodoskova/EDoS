{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "#Load libraries \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>148239.5</th>\n",
       "      <th>1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>149211</th>\n",
       "      <th>1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138135.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>210478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226863.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>228424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210482.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>212674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>233415.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>237036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217035.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>218946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   148239.5         1       0.2  149211  1.1\n",
       "0  138135.0  0.666667  0.466667  210478    1\n",
       "1  226863.0  1.000000  0.200000  228424    1\n",
       "2  210482.0  1.000000  0.200000  212674    1\n",
       "3  233415.0  1.000000  0.200000  237036    1\n",
       "4  217035.0  1.000000  0.200000  218946    1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess dataset\n",
    "df = pd.read_csv('../data/period_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2294, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       148239.5         1       0.2  149211  1.1\n",
       "0     138135.0  0.666667  0.466667  210478    1\n",
       "1     226863.0  1.000000  0.200000  228424    1\n",
       "2     210482.0  1.000000  0.200000  212674    1\n",
       "3     233415.0  1.000000  0.200000  237036    1\n",
       "4     217035.0  1.000000  0.200000  218946    1\n",
       "...        ...       ...       ...     ...  ...\n",
       "2289  151784.0  1.000000  0.200000  101189    1\n",
       "2290  155608.5  1.000000  0.200000  103742    1\n",
       "2291  154385.5  1.000000  0.200000  102924    1\n",
       "2292  154957.0  1.000000  0.200000  103304    1\n",
       "2293  138660.0  1.000000  0.200000   92440    1\n",
       "\n",
       "[2294 rows x 5 columns]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all of the rows from the first four columns of the dataset\n",
    "X = df.values[:,0:4]\n",
    "#X = np.asarray(X).astype('int')\n",
    "# Get all of the rows from the last column\n",
    "y = df.values[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.1, random_state = 4)\n",
    "X_train=np.asarray(X_train).astype(int)\n",
    "y_train=np.asarray(y_train).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dasha/Downloads/Darya DDOA paper simulation/myenv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Model ANN\n",
    "model = Sequential([\n",
    "    Dense(100, activation='relu', input_dim=4),\n",
    "    Dense(150, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.6870 - val_accuracy: 0.6852 - val_loss: 0.6542\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7081 - loss: 0.6279 - val_accuracy: 0.6538 - val_loss: 0.5247\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6690 - loss: 0.5161 - val_accuracy: 0.6538 - val_loss: 0.4717\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.6820 - loss: 0.4755 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.6887 - loss: 0.4778 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.6962 - loss: 0.4761 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.6795 - loss: 0.4812 - val_accuracy: 0.6852 - val_loss: 0.4693\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.6780 - loss: 0.4840 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.6703 - loss: 0.4791 - val_accuracy: 0.6852 - val_loss: 0.4697\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.6817 - loss: 0.4770 - val_accuracy: 0.6852 - val_loss: 0.4696\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.6838 - loss: 0.4755 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.6960 - loss: 0.4553 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.6982 - loss: 0.4591 - val_accuracy: 0.6852 - val_loss: 0.4690\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6865 - loss: 0.4909 - val_accuracy: 0.6852 - val_loss: 0.4692\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.6717 - loss: 0.4939 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.6831 - loss: 0.4606 - val_accuracy: 0.6852 - val_loss: 0.4694\n",
      "Epoch 17/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.6935 - loss: 0.4762 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 18/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.6813 - loss: 0.4852 - val_accuracy: 0.6852 - val_loss: 0.4686\n",
      "Epoch 19/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.6796 - loss: 0.4640 - val_accuracy: 0.6852 - val_loss: 0.4696\n",
      "Epoch 20/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.6938 - loss: 0.4664 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 21/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.7069 - loss: 0.4579 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 22/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.6882 - loss: 0.4841 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 23/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.6767 - loss: 0.4793 - val_accuracy: 0.6852 - val_loss: 0.4693\n",
      "Epoch 24/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6973 - loss: 0.4630 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 25/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.7100 - loss: 0.4665 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 26/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.6805 - loss: 0.4816 - val_accuracy: 0.6852 - val_loss: 0.4686\n",
      "Epoch 27/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.6786 - loss: 0.4909 - val_accuracy: 0.6852 - val_loss: 0.4693\n",
      "Epoch 28/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7023 - loss: 0.4743 - val_accuracy: 0.6852 - val_loss: 0.4692\n",
      "Epoch 29/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.6949 - loss: 0.4678 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 30/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.7148 - loss: 0.4672 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 31/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6798 - loss: 0.4857 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 32/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6758 - loss: 0.4904 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 33/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.6952 - loss: 0.4678 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 34/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.6860 - loss: 0.4745 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 35/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.6913 - loss: 0.4646 - val_accuracy: 0.6852 - val_loss: 0.4690\n",
      "Epoch 36/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.6782 - loss: 0.4801 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 37/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.6764 - loss: 0.4837 - val_accuracy: 0.6852 - val_loss: 0.4686\n",
      "Epoch 38/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.6770 - loss: 0.4808 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 39/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.6748 - loss: 0.4758 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 40/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.6814 - loss: 0.4843 - val_accuracy: 0.6852 - val_loss: 0.4693\n",
      "Epoch 41/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.6868 - loss: 0.4816 - val_accuracy: 0.6852 - val_loss: 0.4690\n",
      "Epoch 42/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7014 - loss: 0.4779 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 43/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.6814 - loss: 0.4771 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 44/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.6929 - loss: 0.4818 - val_accuracy: 0.6852 - val_loss: 0.4692\n",
      "Epoch 45/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.6968 - loss: 0.4664 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 46/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.6863 - loss: 0.4769 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 47/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.6811 - loss: 0.4869 - val_accuracy: 0.6852 - val_loss: 0.4690\n",
      "Epoch 48/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.6970 - loss: 0.4815 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 49/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.6877 - loss: 0.4707 - val_accuracy: 0.6852 - val_loss: 0.4686\n",
      "Epoch 50/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.6897 - loss: 0.4726 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 51/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.6906 - loss: 0.4782 - val_accuracy: 0.6852 - val_loss: 0.4692\n",
      "Epoch 52/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.6825 - loss: 0.4766 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 53/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.6929 - loss: 0.4768 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 54/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.6839 - loss: 0.4859 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 55/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.6900 - loss: 0.4764 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 56/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.6879 - loss: 0.4807 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 57/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.6966 - loss: 0.4674 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 58/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7000 - loss: 0.4719 - val_accuracy: 0.6852 - val_loss: 0.4690\n",
      "Epoch 59/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.6761 - loss: 0.4697 - val_accuracy: 0.6852 - val_loss: 0.4685\n",
      "Epoch 60/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7137 - loss: 0.4548 - val_accuracy: 0.6852 - val_loss: 0.4693\n",
      "Epoch 61/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.7028 - loss: 0.4838 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 62/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7178 - loss: 0.4495 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 63/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.6768 - loss: 0.4865 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 64/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.6960 - loss: 0.4679 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 65/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.6772 - loss: 0.4783 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 66/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.6748 - loss: 0.4776 - val_accuracy: 0.6852 - val_loss: 0.4690\n",
      "Epoch 67/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.6823 - loss: 0.4828 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 68/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.6823 - loss: 0.4748 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 69/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.6732 - loss: 0.5000 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 70/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.6996 - loss: 0.4659 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 71/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.6915 - loss: 0.4697 - val_accuracy: 0.6852 - val_loss: 0.4693\n",
      "Epoch 72/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.6891 - loss: 0.4708 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 73/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.6820 - loss: 0.4797 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 74/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.6950 - loss: 0.4568 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 75/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.6818 - loss: 0.4610 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 76/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.6925 - loss: 0.4699 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 77/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.6967 - loss: 0.4599 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 78/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.6913 - loss: 0.4723 - val_accuracy: 0.6852 - val_loss: 0.4695\n",
      "Epoch 79/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.6742 - loss: 0.4806 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 80/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.6887 - loss: 0.4813 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 81/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.6999 - loss: 0.4682 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 82/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.6949 - loss: 0.4720 - val_accuracy: 0.6852 - val_loss: 0.4690\n",
      "Epoch 83/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.6895 - loss: 0.4733 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 84/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.6787 - loss: 0.4765 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 85/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.6918 - loss: 0.4756 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 86/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.6736 - loss: 0.4831 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 87/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.7027 - loss: 0.4746 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 88/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.6862 - loss: 0.4872 - val_accuracy: 0.6852 - val_loss: 0.4692\n",
      "Epoch 89/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.6829 - loss: 0.4726 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 90/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.6874 - loss: 0.4804 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 91/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.6848 - loss: 0.4817 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 92/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.6974 - loss: 0.4715 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 93/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.6815 - loss: 0.4777 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 94/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.6856 - loss: 0.4787 - val_accuracy: 0.6852 - val_loss: 0.4687\n",
      "Epoch 95/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.6989 - loss: 0.4750 - val_accuracy: 0.6852 - val_loss: 0.4691\n",
      "Epoch 96/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.6976 - loss: 0.4678 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 97/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.6996 - loss: 0.4657 - val_accuracy: 0.6852 - val_loss: 0.4688\n",
      "Epoch 98/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.6603 - loss: 0.4980 - val_accuracy: 0.6852 - val_loss: 0.4690\n",
      "Epoch 99/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.6796 - loss: 0.4817 - val_accuracy: 0.6852 - val_loss: 0.4689\n",
      "Epoch 100/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.6794 - loss: 0.4750 - val_accuracy: 0.6852 - val_loss: 0.4690\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "hist = model.fit(X_train, y_train,\n",
    "          batch_size=57, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"period_model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, scaler):\n",
    "    # Ensure data is in the correct format and scale it using the same scaler\n",
    "    scaled_data = scaler.transform(data)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x295059760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x295059760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Prediction for new data: [[0.4277102]]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = load_model(\"period_model_final.h5\")\n",
    "\n",
    "# Example usage of the model\n",
    "new_data = np.array([[1, 2, 3, 4]])  # Example new data point\n",
    "scaled_new_data = preprocess_data(new_data, min_max_scaler)\n",
    "prediction = model.predict(scaled_new_data)\n",
    "print(f\"Prediction for new data: {prediction}\")\n",
    "\n",
    "# Evaluate model on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 58.7222222222222, 'Predicted')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "y_pred=(model.predict(X_test)>0.5).astype(\"int32\")\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        73\n",
      "         1.0       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       230\n",
      "   macro avg       1.00      1.00      1.00       230\n",
      "weighted avg       1.00      1.00      1.00       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(f'Classification Report: \\n {classification_report(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
