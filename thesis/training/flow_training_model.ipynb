{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X = data.values[:, :-1]\n",
    "y = data.values[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20201</th>\n",
       "      <th>1212000</th>\n",
       "      <th>0.000645609</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19521</td>\n",
       "      <td>1171200</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19245</td>\n",
       "      <td>1154640</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20202</td>\n",
       "      <td>1212060</td>\n",
       "      <td>0.000662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20202</td>\n",
       "      <td>1212060</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20661</td>\n",
       "      <td>1239600</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   20201  1212000  0.000645609\n",
       "0  19521  1171200     0.000659\n",
       "1  19245  1154640     0.000738\n",
       "2  20202  1212060     0.000662\n",
       "3  20202  1212060     0.000671\n",
       "4  20661  1239600     0.000738"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX=pd.read_csv('../data/datasetLSTMX.csv', engine='python')\n",
    "dataX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X = data.values[:, :-1]\n",
    "y = data.values[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dasha/Downloads/Darya DDOA paper simulation/myenv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(12, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(15, activation='relu'),\n",
    "    Dense(18, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Use binary_crossentropy for binary classification\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1952 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 2/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.2062 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 3/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.2265 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 4/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.2132 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 5/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.2087 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 6/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.2262 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 7/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.2093 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 8/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.2335 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 9/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.2174 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 10/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.2297 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 11/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.2167 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 12/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.2140 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 13/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.2219 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 14/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.2177 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 15/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.2051 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 16/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.2106 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 17/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.2194 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 18/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.2216 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 19/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.2325 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 20/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.2009 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 21/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.2180 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 22/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.2211 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 23/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.2265 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 24/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.2129 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 25/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.2038 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 26/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.2190 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 27/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.2179 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 28/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.2312 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 29/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.2048 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 30/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.2164 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 31/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.2008 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 32/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.2173 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 33/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.2261 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 34/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.2170 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 35/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.2141 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 36/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.2110 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 37/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2222 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 38/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.2321 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 39/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.2212 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 40/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.2266 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 41/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.2172 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 42/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.2066 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 43/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.1982 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 44/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.2195 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 45/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.2100 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 46/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.2176 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 47/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.2111 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 48/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.2234 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 49/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.2057 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 50/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.2189 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 51/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.2016 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 52/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.2209 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 53/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.2090 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 54/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.2079 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 55/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.2031 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 56/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.2133 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 57/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.2246 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 58/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.2089 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 59/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.2323 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 60/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.2212 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 61/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.2019 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 62/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.2216 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 63/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.2334 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 64/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.2271 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 65/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.2144 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 66/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.2131 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 67/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.2033 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 68/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.2167 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 69/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.2166 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 70/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.2141 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 71/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.2263 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 72/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.2178 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 73/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.2314 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 74/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.2039 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 75/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.2221 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 76/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.2240 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 77/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.2077 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 78/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.2314 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 79/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.2160 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 80/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.2182 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 81/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.2125 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 82/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.2243 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 83/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.1915 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 84/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.2094 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 85/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.2115 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 86/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.2182 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 87/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.2186 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 88/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.2128 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 89/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.2205 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 90/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.2319 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 91/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.2302 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 92/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.2238 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 93/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.2260 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 94/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.2117 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 95/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.2105 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 96/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.1899 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 97/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.2221 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 98/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.2385 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 99/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.2007 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n",
      "Epoch 100/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.2120 - loss: nan - val_accuracy: 0.1583 - val_loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=57, epochs=100, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "\n",
    "model.save(\"models/model_flow_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/model_flow.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       199\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       0.50      0.50      0.50       200\n",
      "weighted avg       0.99      0.99      0.99       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dasha/Downloads/Darya DDOA paper simulation/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dasha/Downloads/Darya DDOA paper simulation/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dasha/Downloads/Darya DDOA paper simulation/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure y_test has no NaN values\n",
    "y_test = np.nan_to_num(y_test, nan=0)  # Or remove them as needed\n",
    "\n",
    "# Make predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "print(f'Classification Report: \\n {classification_report(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
